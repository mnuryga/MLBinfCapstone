{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c42e0b1",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02e8d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/home/MLI2/MLI2wngk/scratch/miniconda3/envs/binf2/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "from einops import rearrange, repeat\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f28bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPA(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_m, c_z, heads=12, dim_head=None, n_qp=4, n_pv=8):\n",
    "        '''\n",
    "        dim_head: channel C\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        # constants\n",
    "        self.w_c = (2 / (9 * n_qp)) ** -0.5\n",
    "        self.w_l = (1 / 3) ** -0.5\n",
    "        self.n_qp = n_qp\n",
    "        self.n_pv = n_pv\n",
    "        \n",
    "        # single rep attention layers\n",
    "        self.heads = heads\n",
    "        self.dim_head = (int(c_m / heads)) if dim_head is None else dim_head\n",
    "        _dim = self.dim_head * heads\n",
    "        self.to_qvk = nn.Linear(c_m, _dim * 3, bias=False)\n",
    "        self.W_0 = nn.Linear(_dim, c_m, bias=False)\n",
    "        self.to_qk = nn.Linear(c_m, (n_qp * heads *3) * 2, bias=False)\n",
    "        self.W_0 = nn.Linear(_dim, c_m, bias=False)\n",
    "        self.W_1 = nn.Linear(heads * c_z, c_m, bias=False)\n",
    "        self.W_2 = nn.Linear(heads * n_pv * 3, c_m)\n",
    "        self.gamma = nn.Parameter(torch.rand(1))\n",
    "        self.to_v = nn.Linear(c_m, (n_pv * heads * 3), bias=False)\n",
    "        \n",
    "        # pair_rep layers\n",
    "        self.fc1 = nn.Linear(c_z, heads)\n",
    "\n",
    "    def forward(self, pair_rep, sing_rep, bbr, bbt):\n",
    "        '''\n",
    "        bbr: rotational matrix (B x R x 3 x 3)\n",
    "        bbt: translatoin matrix (B x R x 3)\n",
    "        '''\n",
    "        \n",
    "        # pair_rep to pair_bias\n",
    "        pair_bias = self.fc1(pair_rep)\n",
    "        pair_bias = rearrange(pair_bias, 'b i j h -> b h i j')\n",
    "#         print(f'pair bias shape = {pair_bias.shape}')\n",
    "        \n",
    "        ### SINGLE REP SQR ATTENTION\n",
    "        \n",
    "        # get q and v for attention training (B x P x R x H x 3)\n",
    "        qk = self.to_qk(sing_rep)\n",
    "#         print(f'qk shape = {qk.shape}')\n",
    "        gq, gk = tuple(rearrange(qk, 'b r (d k p a) -> k b p r d a', k=2, a=3, p=self.n_qp))\n",
    "#         print(f'qk shape = {gq.shape}')\n",
    "        gv = rearrange(self.to_v(sing_rep), 'b r (d p a) -> b p r d a', a=3, p=self.n_pv)\n",
    "#         print(f'gv shape = {gv.shape}')\n",
    "        \n",
    "        ### SINGLE REP DOT ATTENTION\n",
    "        \n",
    "        # get q, v, k matrices for attention training (B x H x R x C)\n",
    "        qkv = self.to_qvk(sing_rep)\n",
    "#         print(f'qkv shape = {qkv.shape}')\n",
    "        rq, rk, rv = tuple(rearrange(qkv, 'b r (d k h) -> k b h r d', k=3, h=self.heads))\n",
    "#         print(f'qkv shape = {rq.shape}')\n",
    "    \n",
    "        # dot product attention (B x H x R x R)\n",
    "        dot_prod_aff = torch.einsum('b h i d , b h j d -> b h i j', rq, rk) * (self.dim_head ** -0.5)\n",
    "#         print(f'dot_prod_aff shape = {dot_prod_aff.shape}')\n",
    "        \n",
    "        # square dist attention\n",
    "        Tq = torch.einsum('b p r h a , b r a k -> p h b r k', gq, bbr) + bbt\n",
    "        Tk = torch.einsum('b p r h a , b r a k -> p h b r k', gk, bbr) + bbt\n",
    "        \n",
    "        # tile to square and deduct\n",
    "        r = Tq.shape[-2]\n",
    "        Tq = repeat(Tq, 'p h b r k -> p h b r i k', i=r)\n",
    "        Tk = repeat(Tk, 'p h b r k -> p h b i r k', i=r)\n",
    "        sqr_dist_aff = Tq - Tk  # p h b r r k\n",
    "        sqr_dist_aff = rearrange(sqr_dist_aff, 'p h b i j k -> b p h i j k')\n",
    "        # norm square\n",
    "        sqr_dist_aff = torch.sum(torch.square(torch.norm(sqr_dist_aff, dim=-1)), dim=1) # b h r r\n",
    "#         print(f'norm_sqr shape = {sqr_dist_aff.shape}')\n",
    "        # multiply head weight\n",
    "        head_w = (F.softplus(self.gamma.repeat(self.heads)) * self.w_c) / 2\n",
    "#         print(f'head_w shape = {head_w.shape}')\n",
    "#         print(f'sqr_dist_aff shape = {sqr_dist_aff.shape}')        \n",
    "        sqr_dist_aff = rearrange(rearrange(sqr_dist_aff, 'b h i j -> b i j h') * head_w, 'b i j h -> b h i j')\n",
    "#         print(f'sqr_dist_aff shape = {sqr_dist_aff.shape}')\n",
    "        \n",
    "        # sum attentions with bias then softmax (B x H x R x R)\n",
    "        attentions = pair_bias + dot_prod_aff + sqr_dist_aff\n",
    "        attentions = torch.softmax(self.w_l * attentions, dim=-1)\n",
    "#         print(f'attentions after softmax shape = {attentions.shape}')\n",
    "        \n",
    "        \n",
    "        # dot with pair values (top) \n",
    "        # B Rq H R x B Rq R C => B R H C\n",
    "        top = torch.einsum('b h i j , b h j d -> b h i d', rearrange(attentions, 'b h i j -> b i h j'), pair_rep) # B H Rq R x B C R R -> B C R R\n",
    "        # concat heads\n",
    "        top = rearrange(top, 'b r h c -> b r (h c)')\n",
    "#         print(f'top shape = {top.shape}')\n",
    "        # transform back to initial dimension\n",
    "        top = self.W_1(top)\n",
    "        \n",
    "        # dot with value points (bot)\n",
    "        # B H Rq Rv x B P Rv H 3 => B R1 H P 3\n",
    "        Tv = torch.einsum('b p r h a , b r a k -> p h b r k', gv, bbr) + bbt\n",
    "#         print(f'Tv shape = {Tv.shape}')\n",
    "        bot = torch.einsum('b h i j , p h b j a -> b i h p a', attentions, Tv)\n",
    "        # invert backbone frames\n",
    "        bbr_inv = torch.linalg.inv(bbr)\n",
    "        # affine transform\n",
    "        bot = torch.einsum('b r h p a , b r a k -> h p b r k', bot, bbr_inv) + bbt\n",
    "        # concat heads\n",
    "        bot = rearrange(bot, 'h p b r a -> b r (h p a)')\n",
    "        # transform back to initial dimension\n",
    "        bot = self.W_2(bot)\n",
    "#         print(f'bot shape = {bot.shape}')\n",
    "        \n",
    "        # dot with matrix v (mid)\n",
    "        out = torch.einsum('b h i j , b h j d -> b h i d', attentions, rv)        \n",
    "        # concat heads\n",
    "        out = rearrange(out, \"b h t d -> b t (h d)\")\n",
    "        # transform back to initial dimension\n",
    "        out = self.W_0(out)\n",
    "        # sum top, mid, bottom\n",
    "        out = out + top\n",
    "#         print(f'output shape = {out.shape}')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "179349c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 64, 8, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B H Rv Rq x B H Rv P 3\n",
    "a = torch.rand(1,12,64,64)\n",
    "b = torch.rand(1,12,64,8,3)\n",
    "torch.einsum('b h i j , b h i p a -> b h j p a', a, b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9918e94",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa0df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 5\n",
    "R = 64\n",
    "C_m = 128\n",
    "C_z = 64\n",
    "H = 12\n",
    "C = 16\n",
    "N_qp = 4\n",
    "N_pv = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3bb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_rep = torch.rand(B, R, R, C_z)\n",
    "sing_rep = torch.rand(B, R, C_m)\n",
    "bbr = torch.rand(B, R, 3, 3)\n",
    "bbt = torch.rand(B, R, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d8468bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 128])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa = IPA(C_m, C_z, heads=H, dim_head=C)\n",
    "ipa(pair_rep, sing_rep, bbr, bbt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e758f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 128])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sing_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7280a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 64, 64])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e47da9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 3, 3])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2bc6bce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "161c62df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9]],\n",
       "\n",
       "        [[10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.arange(20).reshape(2,2,5)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e773d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = einops.repeat(arr, 'i j k -> i (tile j) k', tile=2)  # in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "93c3b57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0bc9f501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9]],\n",
       "\n",
       "        [[10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19],\n",
       "         [10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50baf0dc",
   "metadata": {},
   "source": [
    "## Structure model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c08815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: torch_batch_svd (https://github.com/KinglittleQ/torch-batch-svd) is not installed and is required for maximum efficiency of special_procrustes. Using torch.svd as a fallback.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Building blocks of the AlphaFold 2 model.\n",
    "\n",
    "Author: Matthew Uryga, Yu-Kai \"Steven\" Wang\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "from einops import rearrange, repeat\n",
    "from scipy.spatial.transform import Rotation\n",
    "from roma import unitquat_to_rotmat\n",
    "\n",
    "class MHSA(nn.Module):\n",
    "    def __init__(self, c_m, c_z, heads=8, dim_head=None, bias=True):\n",
    "        '''\n",
    "        Gated self-attention with or without pair bias\n",
    "        c_m: channel dim target attention\n",
    "        c_z: channel dim of the pair wise bias\n",
    "        heads: number of heads for the multi-head attention\n",
    "        dim_head: channel dim of each head\n",
    "        bias: Apply pair-wise bias or not\n",
    "\n",
    "        Author: Yu-Kai \"Steven\" Wang\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.dim_head = (int(c_m / heads)) if dim_head is None else dim_head\n",
    "        _dim = self.dim_head * heads\n",
    "        self.heads = heads\n",
    "        self.to_qvk = nn.Linear(c_m, _dim * 4, bias=False)\n",
    "        self.W_0 = nn.Linear( _dim, c_m, bias=False)\n",
    "        self.scale_factor = self.dim_head ** -0.5\n",
    "        \n",
    "        self.fc_scale_bias = nn.Linear(c_z, heads)\n",
    "\n",
    "    def forward(self, x, bias_rep=None):\n",
    "        '''\n",
    "        x: input for self-attention\n",
    "        bias_rep: pair-wise bias\n",
    "        '''\n",
    "        # get q, v, k, g matrix for attention training\n",
    "        qkv = self.to_qvk(x)\n",
    "        q, k, v, g = tuple(rearrange(qkv, 'b t (d k h) -> k b h t d ', k=4, h=self.heads))\n",
    "        \n",
    "        # dot product attention\n",
    "        scaled_dot_prod = torch.einsum('b h i d , b h j d -> b h i j', q, k) * self.scale_factor\n",
    "\n",
    "        # pair-wise bias\n",
    "        scaled_bias = 0\n",
    "        if self.bias:\n",
    "            scaled_bias = self.fc_scale_bias(bias_rep)\n",
    "            scaled_bias = rearrange(scaled_bias, 'i j k -> k i j').unsqueeze(0)\n",
    "            \n",
    "        attention = torch.softmax(scaled_dot_prod + scaled_bias, dim=-1)\n",
    "        \n",
    "        # dot product with matrix v\n",
    "        out = torch.einsum('b h i j , b h j d -> b h i d', attention, v)\n",
    "        \n",
    "        # gating\n",
    "        g = torch.sigmoid(g)\n",
    "        out *= g\n",
    "\n",
    "        # concat heads\n",
    "        out = rearrange(out, \"b h t d -> b t (h d)\")\n",
    "\n",
    "        # transform back to initial dimension\n",
    "        return self.W_0(out)\n",
    "\n",
    "class MSA_Stack(nn.Module):\n",
    "    def __init__(self, c_m, c_z, heads=8, dim_head=None):\n",
    "        '''\n",
    "        Do batches of row-wise MHSA with pair bias follow by a column-wise \n",
    "        MHSA without bias. The result is then passed through a two\n",
    "        layer MLP as transition.\n",
    "\n",
    "        Author: Yu-Kai \"Steven\" Wang\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # batches of row wise MHSA\n",
    "        self.row_MHSA = MHSA(c_m=c_m, c_z=c_z, heads=heads, bias=True, dim_head=dim_head)\n",
    "        # batches of col wise MHSA\n",
    "        self.col_MHSA = MHSA(c_m=c_m, c_z=c_z, heads=heads, bias=False, dim_head=dim_head)\n",
    "        # transition MLP\n",
    "        self.fc1 = nn.Linear(c_m, 4 * c_m)\n",
    "        self.fc2 = nn.Linear(4 * c_m, c_m)\n",
    "        # layer norms\n",
    "        self.ln1 = nn.LayerNorm(c_m)\n",
    "        self.ln2 = nn.LayerNorm(c_z)\n",
    "        self.ln3 = nn.LayerNorm(c_m)\n",
    "        \n",
    "    def forward(self, x, bias_rep):\n",
    "        # results\n",
    "        res = torch.empty(x.shape).to(x.get_device())\n",
    "\n",
    "        # layer norms\n",
    "        x = self.ln1(x)\n",
    "        bias_rep = self.ln2(bias_rep)\n",
    "\n",
    "        # row wise gated self-attention with pair bias, loop through batch\n",
    "        for i in range(x.shape[0]):\n",
    "            res[i] = self.row_MHSA(x[i].clone(), bias_rep[i].clone())\n",
    "        x = x + res # add residuals\n",
    "\n",
    "        \n",
    "        # results\n",
    "        res2 = torch.empty(x.shape).to(x.get_device())\n",
    "\n",
    "        # layer norms\n",
    "        x = self.ln3(x)\n",
    "\n",
    "        # column wise gated self-attention\n",
    "        x_trans = rearrange(x, 'b i j k -> b j i k')\n",
    "        for i in range(x_trans.shape[0]):\n",
    "            res2[i] = rearrange(self.col_MHSA(x_trans[i]), 'i j k -> j i k')\n",
    "        x = x + res2 # add residuals\n",
    "\n",
    "        \n",
    "        # transiion\n",
    "        r = F.relu(self.fc1(x))\n",
    "        r = self.fc2(r) + x\n",
    "        \n",
    "        return r\n",
    "\n",
    "class Outer_Product_Mean(nn.Module):\n",
    "    def __init__(self, c_m, c_z, c=32):\n",
    "        '''\n",
    "        Do a linear transform, outer-product, mean,\n",
    "        followed by another linear transform.\n",
    "\n",
    "        Author: Yu-Kai \"Steven\" Wang\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # linear projections\n",
    "        self.fc1 = nn.Linear(c_m, c)\n",
    "        self.fc2 = nn.Linear(c**2, c_z)\n",
    "        self.flatten = nn.Flatten(start_dim=3)\n",
    "        self.c = c\n",
    "        self.c_z = c_z\n",
    "        # layer norms\n",
    "        self.ln = nn.LayerNorm(c_m)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: B x S x R x C\n",
    "        res: B x R x R x C\n",
    "        '''\n",
    "        # results\n",
    "        res = torch.empty(x.shape[0], x.shape[-2], x.shape[-2], self.c, self.c).to(x.get_device())\n",
    "             \n",
    "        # layer norm\n",
    "        x = self.ln(x)\n",
    "        \n",
    "        # project in_c to out_c\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        # loop over R\n",
    "        for i in range(x.shape[-2]):\n",
    "            for j in range(x.shape[-2]):\n",
    "                mean_s = torch.mean(torch.einsum('bij,bik->bijk', [x[:, :, i, :], x[:, :, j, :]]), dim=1)\n",
    "                res[:, i, j, :, :] = mean_s\n",
    "        \n",
    "        # flatten and project back\n",
    "        res = self.flatten(res)\n",
    "        res = self.fc2(res)\n",
    "        \n",
    "        return res\n",
    "                \n",
    "class Pair_Stack(nn.Module):\n",
    "    def __init__(self, c_z, heads=8, dim_head=None):\n",
    "        '''\n",
    "        Do a row-wise MHSA with pair bias on the start edges follow\n",
    "        by a column-wise MHSA with bias on the end edes. The result \n",
    "        is then passed through a two layer MLP as transition.\n",
    "\n",
    "        Author: Yu-Kai \"Steven\" Wang\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # batches of row wise MHSA\n",
    "        self.start_MHSA = MHSA(c_m=c_z, c_z=c_z, heads=heads, bias=True, dim_head=dim_head)\n",
    "        # batches of col wise MHSA\n",
    "        self.end_MHSA = MHSA(c_m=c_z, c_z=c_z, heads=heads, bias=True, dim_head=dim_head)\n",
    "        # transition MLP\n",
    "        self.fc1 = nn.Linear(c_z, 4 * c_z)\n",
    "        self.fc2 = nn.Linear(4 * c_z, c_z)\n",
    "        # layer norms\n",
    "        self.ln1 = nn.LayerNorm(c_z)\n",
    "        self.ln2 = nn.LayerNorm(c_z)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # results\n",
    "        res = torch.empty(x.shape).to(x.get_device())\n",
    "\n",
    "        # layer norms\n",
    "        x = self.ln1(x)\n",
    "\n",
    "        # row wise gated self-attention with pair bias\n",
    "        for i in range(x.shape[0]):\n",
    "            res[i] = self.start_MHSA(x[i].clone(), x[i].clone())\n",
    "        x = x + res # add residuals\n",
    "\n",
    "        \n",
    "        # results\n",
    "        res2 = torch.empty(x.shape).to(x.get_device())\n",
    "\n",
    "        # layer norms\n",
    "        x = self.ln2(x)\n",
    "\n",
    "        # column wise gated self-attention\n",
    "        x_trans = rearrange(x, 'b i j k -> b j i k')\n",
    "        for i in range(x_trans.shape[0]):\n",
    "            res2[i] = rearrange(self.end_MHSA(x_trans[i].clone(), x_trans[i].clone()), 'i j k -> j i k')\n",
    "        x = x + res2 # add residuals\n",
    "\n",
    "        \n",
    "        # transiion\n",
    "        r = F.relu(self.fc1(x))\n",
    "        r = self.fc2(r) + x\n",
    "        \n",
    "        return r\n",
    "\n",
    "class Triangular_Multiplicative_Model(nn.Module):\n",
    "    def __init__(self, direction, c_z = 128, c = 16):\n",
    "        '''\n",
    "        Do batches of triangular multiplication\n",
    "\n",
    "        Author: Matthew Uryga\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.c = c\n",
    "        self.direction = direction\n",
    "        self.ln1 = nn.LayerNorm(c_z)\n",
    "        self.la1 = nn.Linear(c_z, c)\n",
    "        self.la2 = nn.Linear(c_z, c)\n",
    "        self.lb1 = nn.Linear(c_z, c)\n",
    "        self.lb2 = nn.Linear(c_z, c)\n",
    "        self.ln2 = nn.LayerNorm(c)\n",
    "        self.lg = nn.Linear(c_z, c_z)\n",
    "        self.lz = nn.Linear(c, c_z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.ln1(x)\n",
    "        z = x\n",
    "        a = torch.sigmoid(torch.mul(self.la1(z), self.la2(z)))\n",
    "        b = torch.sigmoid(torch.mul(self.lb1(z), self.lb2(z)))\n",
    "        if self.direction == 'incoming':\n",
    "            a = rearrange(a, 'b i j k -> b j i k')\n",
    "            b = rearrange(b, 'b i j k -> b j i k')\n",
    "        g = torch.sigmoid(self.lg(z))\n",
    "        z = torch.zeros((z.shape[0], z.shape[1], z.shape[2], self.c)).to(x.get_device())\n",
    "        for i in range(a.shape[1]):\n",
    "            for j in range(b.shape[2]):\n",
    "                ai = a[:, i, :]\n",
    "                bj = b[:, :, j]\n",
    "                z[:, i, j] = torch.sum(torch.mul(ai, bj), dim = -2)\n",
    "        z = torch.mul(g, self.lz(self.ln2(z)))\n",
    "        return z\n",
    "\n",
    "class PSSM_Projector(nn.Module):\n",
    "    '''\n",
    "    model to project pssm data to s layers\n",
    "\n",
    "    Author: Matthew Uryga\n",
    "    '''\n",
    "    def __init__(self, num_layers, c_m):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(21, c_m) for i in range(num_layers)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.c_m = c_m\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.zeros((x.shape[0], self.num_layers, x.shape[1], self.c_m)).to(x.get_device())\n",
    "        # for each batch, apply a linear layer to pssm data\n",
    "        for i in range(x.shape[0]):\n",
    "            for j, l in enumerate(self.layers):\n",
    "                out[i,j] = l(x[i])\n",
    "        return out\n",
    "\n",
    "class Input_Feature_Projector(nn.Module):\n",
    "    '''\n",
    "    projects the input features to c_2 features\n",
    "\n",
    "    Author: Matthew Uryga\n",
    "    '''\n",
    "    def __init__(self, c_2):\n",
    "        super().__init__()\n",
    "        self.c_2 = c_2\n",
    "        self.l1 = nn.Linear(21, c_2)\n",
    "        self.l2 = nn.Linear(21, c_2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # pass input thorugh linear layers\n",
    "        x1 = self.l1(x)\n",
    "        x2 = self.l2(x)\n",
    "        return x1, x2\n",
    "\n",
    "class Residue_Index_Projector(nn.Module):\n",
    "    '''\n",
    "    projects onehot residue input to c_2 features\n",
    "\n",
    "    Author: Matthew Uryga\n",
    "    '''\n",
    "    def __init__(self, c_2):\n",
    "        super().__init__()\n",
    "        self.l = nn.Linear(65, c_2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # pass through linear layer\n",
    "        return self.l(x)\n",
    "\n",
    "class Representation_Projector(nn.Module):\n",
    "    def __init__(self, r, s, c_m, c_z):\n",
    "        '''\n",
    "        Takes in batch of sequences and evos, and \n",
    "        computes the outer-sum and the relative \n",
    "        positional encoding. The PSSM is ran through \n",
    "        s different linear projection layers to\n",
    "        construct the MSA representation.\n",
    "\n",
    "        Author Matthew Uryga\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "        self.s = s\n",
    "        self.c_m = c_m\n",
    "        self.c_z = c_z\n",
    "        self.pssm_projector = PSSM_Projector(s, c_m)\n",
    "        self.input_feature_projector = Input_Feature_Projector(c_z)\n",
    "        self.residue_index_projector = Residue_Index_Projector(c_z)\n",
    "    \n",
    "    def forward(self, seqs, evos):\n",
    "        L = seqs.shape[1]\n",
    "        # get pssm data projections\n",
    "        msa_reps = self.pssm_projector(evos)\n",
    "\n",
    "        # get residue index and target feat projections\n",
    "        li, lj = self.input_feature_projector(seqs.float())\n",
    "\n",
    "        # calculate outer sum\n",
    "        li = repeat(li, 'b i c -> b rep i c', rep = L)\n",
    "        lj = repeat(lj, 'b i c -> b rep i c', rep = L)\n",
    "        lj = rearrange(lj, 'b i j c -> b j i c')\n",
    "        outer_sum = torch.add(li, lj)\n",
    "\n",
    "        # calculate relative positional encodings\n",
    "        all_res = torch.arange(L).to(seqs.get_device())\n",
    "        di = repeat(all_res, 'i -> rep i', rep = L)\n",
    "        dj = repeat(-all_res, 'j -> rep j', rep = L)\n",
    "        dj = rearrange(dj, 'i j -> j i')\n",
    "\n",
    "        # clamp differences and encode as onehot\n",
    "        d = torch.add(torch.clamp(torch.add(di, dj), -32, 32), 32)\n",
    "        d = F.one_hot(d)\n",
    "\n",
    "        # pass through linear layer\n",
    "        relpos_encoding = self.residue_index_projector(d.float())\n",
    "\n",
    "        # create pairwise representation\n",
    "        prw_reps = torch.add(outer_sum, relpos_encoding)\n",
    "\n",
    "        return prw_reps, msa_reps\n",
    "\n",
    "class Evoformer_Trunk(nn.Module):\n",
    "    '''\n",
    "    evoformer trunk as outlined in the alphafold2 paper\n",
    "\n",
    "    Author: Matthew Uryga\n",
    "    '''\n",
    "    def __init__(self, c_m, c_z, c):\n",
    "        super().__init__()\n",
    "        self.msa_stack = MSA_Stack(c_m, c_z, heads = 4, dim_head = c)\n",
    "        self.outer_product_mean = Outer_Product_Mean(c_m, c_z, c = c)\n",
    "        self.triangular_mult_outgoing = Triangular_Multiplicative_Model('outgoing', c_z = c_z, c = c)\n",
    "        self.triangular_mult_incoming = Triangular_Multiplicative_Model('incoming', c_z = c_z, c = c)\n",
    "        self.pair_stack = Pair_Stack(c_z, heads = 4, dim_head = c)\n",
    "\n",
    "    def forward(self, prw_rep, msa_rep):\n",
    "        # pass msa through attention module\n",
    "        msa_rep = self.msa_stack(msa_rep, prw_rep)\n",
    "\n",
    "        # calculate outer product of msa and add residual\n",
    "        x = self.outer_product_mean(msa_rep) + prw_rep\n",
    "\n",
    "        # pass through triangular multipication for \n",
    "        # outgoing and incoming edges\n",
    "        x = self.triangular_mult_outgoing(x) + x\n",
    "        x = self.triangular_mult_incoming(x) + x\n",
    "\n",
    "        # pass pairwise rep through attention module\n",
    "        prw_rep = self.pair_stack(x) + x\n",
    "        return prw_rep, msa_rep\n",
    "    \n",
    "class Evo_Model(nn.Module):\n",
    "    '''\n",
    "    DEPRECATED\n",
    "\n",
    "    Wrapper class for all the building blocks of the model.\n",
    "    Takes care of the input embeddings, alphafold model pipeline,\n",
    "    and finally dmat and angle predictions.\n",
    "\n",
    "    Author: Matthew Uryga\n",
    "    '''\n",
    "    def __init__(self, r, s, c_m, c_z, c):\n",
    "        super().__init__()\n",
    "        self.rep_proj = Representation_Projector(r, s, c_m, c_z)\n",
    "        self.evoformer_trunk = Evoformer_Trunk(c_m, c_z, c)\n",
    "        self.proj_dmat = nn.Conv2d(c_z, 64, 1)\n",
    "        self.angs_pool = nn.MaxPool2d((1, 64))\n",
    "        self.proj_angs = nn.Conv2d(c_z, 1296, 1)\n",
    "    \n",
    "    def forward(self, seqs, evos):\n",
    "        prw_rep, msa_rep = self.rep_proj(seqs, evos)\n",
    "        prw_rep, msa_rep = self.evoformer_trunk(prw_rep, msa_rep)\n",
    "        c_first = rearrange(prw_rep, 'b i j c -> b c i j')\n",
    "        pred_dmat = self.proj_dmat(c_first)\n",
    "        pred_angs = self.proj_angs(self.angs_pool(c_first))\n",
    "        return pred_dmat, pred_angs.squeeze(-1)\n",
    "\n",
    "class IPA_Module(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_m, c_z, heads=12, dim_head=None, n_qp=4, n_pv=8):\n",
    "        '''\n",
    "        dim_head: channel C\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        # constants\n",
    "        self.w_c = (2 / (9 * n_qp)) ** -0.5\n",
    "        self.w_l = (1 / 3) ** -0.5\n",
    "        self.n_qp = n_qp\n",
    "        self.n_pv = n_pv\n",
    "        \n",
    "        # single rep attention layers\n",
    "        self.heads = heads\n",
    "        self.dim_head = (int(c_m / heads)) if dim_head is None else dim_head\n",
    "        _dim = self.dim_head * heads\n",
    "        self.to_qvk = nn.Linear(c_m, _dim * 3, bias=False)\n",
    "        self.W_0 = nn.Linear(_dim, c_m, bias=False)\n",
    "        self.to_qk = nn.Linear(c_m, (n_qp * heads *3) * 2, bias=False)\n",
    "        self.W_0 = nn.Linear(_dim, c_m, bias=False)\n",
    "        self.W_1 = nn.Linear(heads * c_z, c_m, bias=False)\n",
    "        self.W_2 = nn.Linear(heads * n_pv * 3, c_m)\n",
    "        self.gamma = nn.Parameter(torch.rand(1))\n",
    "        self.to_v = nn.Linear(c_m, (n_pv * heads * 3), bias=False)\n",
    "        \n",
    "        # pair_rep layers\n",
    "        self.fc1 = nn.Linear(c_z, heads)\n",
    "\n",
    "    def forward(self, pair_rep, sing_rep, bbr, bbt):\n",
    "        '''\n",
    "        bbr: rotational matrix (B x R x 3 x 3)\n",
    "        bbt: translatoin matrix (B x R x 3)\n",
    "        '''\n",
    "        \n",
    "        # pair_rep to pair_bias\n",
    "        pair_bias = self.fc1(pair_rep)\n",
    "        pair_bias = rearrange(pair_bias, 'b i j h -> b h i j')\n",
    "#         print(f'pair bias shape = {pair_bias.shape}')\n",
    "        \n",
    "        ### SINGLE REP SQR ATTENTION\n",
    "        \n",
    "        # get q and v for attention training (B x P x R x H x 3)\n",
    "        qk = self.to_qk(sing_rep)\n",
    "#         print(f'qk shape = {qk.shape}')\n",
    "        gq, gk = tuple(rearrange(qk, 'b r (d k p a) -> k b p r d a', k=2, a=3, p=self.n_qp))\n",
    "#         print(f'qk shape = {gq.shape}')\n",
    "        gv = rearrange(self.to_v(sing_rep), 'b r (d p a) -> b p r d a', a=3, p=self.n_pv)\n",
    "#         print(f'gv shape = {gv.shape}')\n",
    "        \n",
    "        ### SINGLE REP DOT ATTENTION\n",
    "        \n",
    "        # get q, v, k matrices for attention training (B x H x R x C)\n",
    "        qkv = self.to_qvk(sing_rep)\n",
    "#         print(f'qkv shape = {qkv.shape}')\n",
    "        rq, rk, rv = tuple(rearrange(qkv, 'b r (d k h) -> k b h r d', k=3, h=self.heads))\n",
    "#         print(f'qkv shape = {rq.shape}')\n",
    "    \n",
    "        # dot product attention (B x H x R x R)\n",
    "        dot_prod_aff = torch.einsum('b h i d , b h j d -> b h i j', rq, rk) * (self.dim_head ** -0.5)\n",
    "#         print(f'dot_prod_aff shape = {dot_prod_aff.shape}')\n",
    "        \n",
    "        # square dist attention\n",
    "        Tq = torch.einsum('b p r h a , b r a k -> p h b r k', gq, bbr) + bbt\n",
    "        Tk = torch.einsum('b p r h a , b r a k -> p h b r k', gk, bbr) + bbt\n",
    "        \n",
    "        # tile to square and deduct\n",
    "        r = Tq.shape[-2]\n",
    "        Tq = repeat(Tq, 'p h b r k -> p h b r i k', i=r)\n",
    "        Tk = repeat(Tk, 'p h b r k -> p h b i r k', i=r)\n",
    "        sqr_dist_aff = Tq - Tk  # p h b r r k\n",
    "        sqr_dist_aff = rearrange(sqr_dist_aff, 'p h b i j k -> b p h i j k')\n",
    "        # norm square\n",
    "        sqr_dist_aff = torch.sum(torch.square(torch.norm(sqr_dist_aff, dim=-1)), dim=1) # b h r r\n",
    "#         print(f'norm_sqr shape = {sqr_dist_aff.shape}')\n",
    "        # multiply head weight\n",
    "        head_w = (F.softplus(self.gamma.repeat(self.heads)) * self.w_c) / 2\n",
    "#         print(f'head_w shape = {head_w.shape}')\n",
    "#         print(f'sqr_dist_aff shape = {sqr_dist_aff.shape}')        \n",
    "        sqr_dist_aff = rearrange(rearrange(sqr_dist_aff, 'b h i j -> b i j h') * head_w, 'b i j h -> b h i j')\n",
    "#         print(f'sqr_dist_aff shape = {sqr_dist_aff.shape}')\n",
    "        \n",
    "        # sum attentions with bias then softmax (B x H x R x R)\n",
    "        attentions = pair_bias + dot_prod_aff + sqr_dist_aff\n",
    "        attentions = torch.softmax(self.w_l * attentions, dim=-1)\n",
    "#         print(f'attentions after softmax shape = {attentions.shape}')\n",
    "        \n",
    "        \n",
    "        # dot with pair values (top) \n",
    "        # B Rq H R x B Rq R C => B R H C\n",
    "        top = torch.einsum('b h i j , b h j d -> b h i d', rearrange(attentions, 'b h i j -> b i h j'), pair_rep) # B H Rq R x B C R R -> B C R R\n",
    "        # concat heads\n",
    "        top = rearrange(top, 'b r h c -> b r (h c)')\n",
    "#         print(f'top shape = {top.shape}')\n",
    "        # transform back to initial dimension\n",
    "        top = self.W_1(top)\n",
    "        \n",
    "        # dot with value points (bot)\n",
    "        # B H Rq Rv x B P Rv H 3 => B R1 H P 3\n",
    "        Tv = torch.einsum('b p r h a , b r a k -> p h b r k', gv, bbr) + bbt\n",
    "#         print(f'Tv shape = {Tv.shape}')\n",
    "        bot = torch.einsum('b h i j , p h b j a -> b i h p a', attentions, Tv)\n",
    "        # invert backbone frames\n",
    "        bbr_inv = torch.linalg.inv(bbr)\n",
    "        # affine transform\n",
    "        bot = torch.einsum('b r h p a , b r a k -> h p b r k', bot, bbr_inv) + bbt\n",
    "        # concat heads\n",
    "        bot = rearrange(bot, 'h p b r a -> b r (h p a)')\n",
    "        # transform back to initial dimension\n",
    "        bot = self.W_2(bot)\n",
    "#         print(f'bot shape = {bot.shape}')\n",
    "        \n",
    "        # dot with matrix v (mid)\n",
    "        out = torch.einsum('b h i j , b h j d -> b h i d', attentions, rv)        \n",
    "        # concat heads\n",
    "        out = rearrange(out, \"b h t d -> b t (h d)\")\n",
    "        # transform back to initial dimension\n",
    "        out = self.W_0(out)\n",
    "        # sum top, mid, bottom\n",
    "        out = out + top\n",
    "#         print(f'output shape = {out.shape}')\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Backbone_Update(nn.Module):\n",
    "    def __init__(self, c_s):\n",
    "        super().__init__()\n",
    "        self.proj_down = nn.Linear(c_s, 6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, r, c_s = x.shape\n",
    "        x = self.proj_down(x)\n",
    "        t = x[:, :, -3:]\n",
    "        q = torch.ones((b, r, 4)).to(x.get_device())\n",
    "        q[:, :, 1:] = x[:, :, :3]\n",
    "        q_coeff = torch.sqrt(1 + torch.square(q[:, :, 1]) + torch.square(q[:, :, 2]) + torch.square(q[:, :, 3]))\n",
    "        q_coeff = torch.tile(q_coeff.unsqueeze(-1), (1, 1, 4))\n",
    "        q[:, :, 0] = q[:, :, 0].div(q_coeff[:, :, 0])\n",
    "        q[:, :, 1:] = q[:, :, 1:].div(q_coeff[:, :, 1:])\n",
    "        r = unitquat_to_rotmat(q)\n",
    "        # r = torch.zeros((b, r, 3, 3)).to(x.get_device())\n",
    "        # for i in range(b):\n",
    "        #   r[i] = Rotation.from_quat(q[i])\n",
    "        return r, t\n",
    "\n",
    "class Structure_Module(nn.Module):\n",
    "    '''\n",
    "    Structure module as outlined in alphafold2 paper\n",
    "    Takes pair rep and single rep to produce predictions for\n",
    "    backbone frames and angles\n",
    "\n",
    "    Author: Matthew Uryga\n",
    "    '''\n",
    "    def __init__(self, r, c_s, c_z, c = 64, N_layer = 8):\n",
    "        super().__init__()\n",
    "        self.N_layer = N_layer\n",
    "        self.c = c\n",
    "        self.dropout = nn.Dropout(p = 0.1)\n",
    "\n",
    "        # layer norms for inputs\n",
    "        self.ln_s_i = nn.LayerNorm(c_s)\n",
    "        self.ln_z = nn.LayerNorm(c_z)\n",
    "\n",
    "        # linear layer for single rep\n",
    "        self.lin_s = nn.Linear(c_s, c_s)\n",
    "\n",
    "        # ipa module and its layer norm\n",
    "        self.ipa_module = IPA_Module(c_s, c_z)\n",
    "        self.ln_ipa = nn.LayerNorm(c_s)\n",
    "\n",
    "        # transition\n",
    "        # ffn and layer norm for output of ipa module\n",
    "        self.lin_s1 = nn.Linear(c_s, c_s)\n",
    "        self.lin_s2 = nn.Linear(c_s, c_s)\n",
    "        self.lin_s3 = nn.Linear(c_s, c_s)\n",
    "        self.ln_s = nn.LayerNorm(c_s)\n",
    "\n",
    "        # update backbone\n",
    "        self.bb_update = Backbone_Update(c_s)\n",
    "\n",
    "        # predict sidechain and backbone torsion angles\n",
    "        # linear projections to dim c\n",
    "        self.lin_a1 = nn.Linear(c_s, c)\n",
    "        self.lin_a2 = nn.Linear(c_s, c)\n",
    "\n",
    "        # ffn 1 for a\n",
    "        self.lin_a3 = nn.Linear(c, c)\n",
    "        self.lin_a4 = nn.Linear(c, c)\n",
    "\n",
    "        # ffn 2 for a\n",
    "        self.lin_a5 = nn.Linear(c, c)\n",
    "        self.lin_a6 = nn.Linear(c, c)\n",
    "\n",
    "        # project down to dim 4 for torsion angles\n",
    "        # 0, 1 represent phi, 2, 3 represent psi\n",
    "        self.lin_a7 = nn.Linear(c, 4)\n",
    "\n",
    "        self.loss_func = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def compute_fape(self, bb_r, bb_t, x, T_labels, x_labels, eps = 1e-4):\n",
    "        '''\n",
    "        bb_r: (B x R x 3 x 3)\n",
    "        bb_t: (B x R x 3)\n",
    "        x: (B x R x 3)\n",
    "        '''\n",
    "        \n",
    "        # split labels\n",
    "        bb_r_labels, bb_t_labels = T_labels\n",
    "\n",
    "        # get dimensions\n",
    "        B, I, _, _ = bb_r.shape\n",
    "        J = x.shape[1]\n",
    "#         x = x.unsqueeze(-1)\n",
    "\n",
    "        # create x_ij matrices (B x R x R x 3)\n",
    "        x_ij = torch.zeros((B, I, J, 3)).to(bb_r.get_device())\n",
    "        x_ij_labels = torch.zeros((B, I, J, 3)).to(bb_r.get_device())\n",
    "        \n",
    "        ######## CHANGE ########\n",
    "        bb_r_inv = torch.linalg.inv(bb_r)\n",
    "        bb_r_labels_inv = torch.linalg.inv(bb_r_labels)\n",
    "        print(x.shape)\n",
    "        print(bb_r_inv.shape)\n",
    "        x_ij = torch.einsum('b i l m , b j l -> i b j m', bb_r_inv, x) + bb_t\n",
    "        x_ij = rearrange(x_ij, 'i b j m -> b i j m')\n",
    "        x_ij_labels = torch.einsum('b i l m , b j l -> i b j m', bb_r_labels_inv, x) + bb_t_labels\n",
    "        x_ij_labels = rearrange(x_ij_labels, 'i b j m -> b i j m')\n",
    "\n",
    "#       for i in range(I):\n",
    "#           for j in range(J):\n",
    "#               x_ij[:, i, j] = torch.bmm(torch.linalg.inv(bb_r[:, i]), x[:, j]).squeeze() + bb_t[:, i]\n",
    "#               x_ij_labels[:, i, j] = torch.bmm(torch.linalg.inv(bb_r_labels[:, i]), x[:, j]).squeeze() + bb_t_labels[:, i]\n",
    "\n",
    "        # calculate d\n",
    "        d = torch.sqrt(F.mse_loss(x_ij, x_ij_labels, reduction = 'none') + eps)\n",
    "\n",
    "        # calculate fape\n",
    "        d[d > 10] = 10\n",
    "        fape = 0.1 * torch.mean(d)\n",
    "\n",
    "        # return\n",
    "        return fape\n",
    "\n",
    "\n",
    "    def forward(self, z, s_i, a_labels, T_labels, x_labels):\n",
    "        b, r, c_s = s_i.shape\n",
    "        # apply layer norms to input\n",
    "        s_i = self.ln_s_i(s_i)\n",
    "        z = self.ln_z(z)\n",
    "\n",
    "        # pass single rep through linear layer\n",
    "        s = self.lin_s(s_i)\n",
    "\n",
    "        # black hole initialization\n",
    "        bb_r = torch.zeros((b, r, 3, 3)).to(z.get_device())\n",
    "        for i in range(3):\n",
    "            bb_r[:, :, i, i] = 1\n",
    "        bb_t = torch.zeros((b, r, 3)).to(z.get_device())\n",
    "\n",
    "        L_aux = torch.zeros((self.N_layer))\n",
    "        # loop over N_layers\n",
    "        for l in range(self.N_layer):\n",
    "            # pass through ipa module\n",
    "            # s = self.ipa_module(z, s, bb_r, bb_t) + s\n",
    "\n",
    "            # apply layer norm and dropout\n",
    "            s = self.ln_ipa(self.dropout(s))\n",
    "\n",
    "            # transition\n",
    "            # pass through ffn\n",
    "            s_t = F.relu(self.lin_s1(s))\n",
    "            s_t = F.relu(self.lin_s2(s_t))\n",
    "            s = self.lin_s3(s_t) + s\n",
    "\n",
    "            # apply layer norm and dropout\n",
    "            s = self.ln_s(self.dropout(s))\n",
    "\n",
    "            # update backbone\n",
    "            new_r, new_t = self.bb_update(s)\n",
    "            bb_r = torch.matmul(bb_r, new_r)\n",
    "            bb_t = torch.add(bb_t, new_t)\n",
    "\n",
    "            # torsion angle prediction\n",
    "            a = self.lin_a1(s) + self.lin_a2(s_i)\n",
    "            a = self.lin_a3(F.relu(self.lin_a4(F.relu(a)))) + a\n",
    "            a = self.lin_a5(F.relu(self.lin_a6(F.relu(a)))) + a\n",
    "            a = self.lin_a7(F.relu(a))\n",
    "\n",
    "            # calculate torsion angle loss\n",
    "            l_phi = torch.sqrt(torch.square(a[:, :, 0]) + torch.square(a[:, :, 1]))\n",
    "            l_psi = torch.sqrt(torch.square(a[:, :, 2]) + torch.square(a[:, :, 3]))\n",
    "            l_phi = torch.tile(l_phi.unsqueeze(-1), (1, 1, 2))\n",
    "            l_psi = torch.tile(l_psi.unsqueeze(-1), (1, 1, 2))\n",
    "            a[:, :, :2] = a[:, :, :2]/l_phi\n",
    "            a[:, :, 2:] = a[:, :, 2:]/l_psi\n",
    "            L_torsion = self.loss_func(a, a_labels)\n",
    "            L_anglenorm = torch.mean(torch.abs(l_phi - 1) + torch.abs(l_psi - 1))\n",
    "            L_torsion = L_torsion + 0.02*L_anglenorm\n",
    "\n",
    "            # calculate FAPE\n",
    "            x = bb_t\n",
    "            L_fape = self.compute_fape(bb_r, bb_t, x, T_labels, x_labels, eps = 1e-12)\n",
    "\n",
    "            # sum fape and torsion loss for aux loss\n",
    "            L_aux[l] = L_fape + L_torsion\n",
    "\n",
    "        # mean of L_aux \n",
    "        L_aux = torch.mean(L_aux)\n",
    "\n",
    "        # final loss on final coordinates\n",
    "        L_fape = self.compute_fape(bb_r, bb_t, x, T_labels, x_labels, eps = 1e-4)\n",
    "\n",
    "        return x, L_fape, L_aux\n",
    "\n",
    "\n",
    "class Alphafold2_Model(nn.Module):\n",
    "    '''\n",
    "    Module to wrap the entire alphafold2 model\n",
    "    Includes input embeddings/projections, evoformer trunk, and IPA model\n",
    "\n",
    "    Author: Matthew Uryga, Yu-Kai \"Steven\" Wang\n",
    "    '''\n",
    "    def __init__(self, r, s, c_m, c_z, c):\n",
    "        super().__init__()\n",
    "        self.rep_proj = Representation_Projector(r, s, c_m, c_z)\n",
    "        self.evoformer_trunk = Evoformer_Trunk(c_m, c_z, c)\n",
    "        self.structure_module = Structure_Module(r, c_m, c_z, c = c)\n",
    "    \n",
    "    def forward(self, seqs, evos, a_labels, T_labels, x_labels):\n",
    "        # pass input through projections\n",
    "        prw_rep, msa_rep = self.rep_proj(seqs, evos)\n",
    "\n",
    "        # pass representations through evoformer trunk\n",
    "        prw_rep, msa_rep = self.evoformer_trunk(prw_rep, msa_rep)\n",
    "\n",
    "        # pass updated representations through structure module\n",
    "        x, L_fape, L_aux = self.structure_module(prw_rep, msa_rep[:, 0], a_labels, T_labels, x_labels)\n",
    "        return x, L_fape, L_aux\n",
    "\n",
    "# def main():\n",
    "#   device = f'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "#   print(f\"using device: {device}\")\n",
    "#   model = Alphafold2_Model(64, 8, 128, 64, 64).to(device)\n",
    "#   seqs = torch.rand(5, 64, 21).to(device)\n",
    "#   evos = torch.rand(5, 64, 21).to(device)\n",
    "#   a_labels = torch.rand(5, 64, 4).to(device)\n",
    "#   T_labels = (torch.rand(5, 64, 3, 3).to(device), torch.rand(5, 64, 3).to(device))\n",
    "#   x_labels = torch.rand(5, 64, 3).to(device)\n",
    "#   x, L_fape, L_aux = model(seqs, evos, a_labels, T_labels, x_labels)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5786275",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 16\n",
    "B = 32\n",
    "R = 64\n",
    "C_m = 128\n",
    "C_z = 64\n",
    "H = 12\n",
    "C = 16\n",
    "N_qp = 4\n",
    "N_pv = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8753341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_rep = torch.rand(B, S, R, C_m).cuda()\n",
    "prw_rep = torch.rand(B, R, R, C_z).cuda()\n",
    "bbr = torch.rand(B, R, 3, 3).cuda()\n",
    "bbt = torch.rand(B, R, 3).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856a53f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_labels = torch.rand(B, R, 4).cuda()\n",
    "T_labels = (torch.rand(B, R, 3, 3).cuda(), torch.rand(B, R, 3).cuda())\n",
    "x_labels = torch.rand(B, R, 3).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3dbb17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 64, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "86.6 ms ± 3.58 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "structure_module = Structure_Module(R, C_m, C_z, c=C).cuda()\n",
    "x, L_fape, L_aux = structure_module(prw_rep, msa_rep[:, 0], a_labels, T_labels, x_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e719a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
